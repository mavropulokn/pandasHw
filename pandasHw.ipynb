{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbDqe9V5qd228XpJ8pJ94F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavropulokn/pandasHw/blob/main/pandasHw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvD7Qj0d6xaf"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class FeatureGenerator:\n",
        "    def __init__(self, df_train_path, df_questions_path, df_lectures_path, skip_blank_lines=True, nrows=None):\n",
        "        pd.options.display.max_columns = 100\n",
        "        self.df_train = pd.read_csv(df_train_path, skip_blank_lines=skip_blank_lines, nrows=nrows)\n",
        "        self.df_lectures = pd.read_csv(df_lectures_path, skip_blank_lines=skip_blank_lines, nrows=nrows)\n",
        "        self.df_questions = pd.read_csv(df_questions_path, skip_blank_lines=skip_blank_lines, nrows=nrows)\n",
        "        self.df_merged = None\n",
        "\n",
        "    def generate(self):\n",
        "        self.clear_data()\n",
        "        self.merge_atomise_dataframes()\n",
        "        self.analyze_create_features()\n",
        "        self.select_features()\n",
        "\n",
        "    def clear_data(self):\n",
        "        print(datetime.utcnow(), \": <-- Очистка данных -->\")\n",
        "\n",
        "        \"\"\"По условию значения df_train prior_question_elapsed_time, user_answer, answered_correctly и\n",
        "              prior_question_elapsed_time отсутствуют для лекций, поэтому очистим лишь прочие строки df_train\"\"\"\n",
        "        self.df_train = self.df_train[self.df_train['row_id'].notna()\n",
        "                                      & self.df_train['timestamp'].notna()\n",
        "                                      & self.df_train['user_id'].notna()\n",
        "                                      & self.df_train['content_id'].notna()\n",
        "                                      & self.df_train['content_type_id'].notna()\n",
        "                                      & self.df_train['task_container_id'].notna()]\n",
        "\n",
        "        self.df_train = self.clear_data_auxiliary(self.df_train, \"df_train\", False)\n",
        "        self.df_questions = self.clear_data_auxiliary(self.df_questions, \"df_questions\")\n",
        "        self.df_lectures = self.clear_data_auxiliary(self.df_lectures, \"df_lectures\")\n",
        "\n",
        "        print(\"Выведем первые три строки и посмотрим, насколько полезны столбцы:\")\n",
        "        print(\"---------------------------------------------------------\")\n",
        "        display(self.df_train.head(3))\n",
        "        display(self.df_questions.head(3))\n",
        "        display(self.df_lectures.head(3))\n",
        "        print(\"---------------------------------------------------------\")\n",
        "\n",
        "        \"\"\"Удалим столбец type_of из df_lectures, краткое описание лекции,\n",
        "              поскольку качественная обработка данных значений \n",
        "              может потребовать глубокого использования инструментов NLP,\n",
        "              например лемматизации или стемматизации\"\"\"\n",
        "        self.df_lectures = self.df_lectures.drop('type_of', axis=1)\n",
        "\n",
        "        \"\"\"Удалим столбец user_answer из df_train,\n",
        "              поскольку нам интересны лишь результаты ответа, а тип интерактивности\n",
        "              можно вывести df_train content_type_id\"\"\"\n",
        "        self.df_train = self.df_train.drop('user_answer', axis=1)\n",
        "\n",
        "        \"\"\"Удалим столбец correct_answer из df_questions,\"\n",
        "              поскольку верный ответ или нет уже известно из df_train answered_correctly\"\"\"\n",
        "        self.df_questions = self.df_questions.drop('correct_answer', axis=1)\n",
        "\n",
        "        print(datetime.utcnow(), \": <-- Очистка данных завершена -->\")\n",
        "\n",
        "    def merge_atomise_dataframes(self):\n",
        "        print(datetime.utcnow(), \": <-- Объединение датафреймов в один и приведение к атомарности значений -->\")\n",
        "\n",
        "        print(\"Выведем типы для train dataframe: \", self.df_train.dtypes)\n",
        "\n",
        "        \"\"\"Объединим датафреймы, добавив к train, преобразуем к атомарности значения столбцов.\"\"\"\n",
        "        self.df_merged = self.df_train.merge(self.df_questions, how=\"left\", left_on='content_id',\n",
        "                                             right_on=\"question_id\")\n",
        "        self.df_merged = self.df_merged.drop('question_id', axis=1)\n",
        "        self.df_merged = self.df_merged.rename(columns={'tags': 'tag_question'})\n",
        "        self.df_train = None\n",
        "        self.df_questions = None\n",
        "\n",
        "        self.df_merged = self.df_merged.merge(self.df_lectures, how=\"left\", left_on='content_id',\n",
        "                                              right_on=\"lecture_id\", suffixes=(\"\", \"_lecture\"))\n",
        "        self.df_merged = self.df_merged.drop('lecture_id', axis=1)\n",
        "        self.df_merged = self.df_merged.rename(columns={'tag': 'tag_lecture'})\n",
        "\n",
        "        self.df_lectures = None\n",
        "\n",
        "        self.df_merged['tag_question'] = self.df_merged['tag_question'].str.split(\" \")\n",
        "        self.df_merged = self.df_merged.explode('tag_question')  # приведем значения к атомарным\n",
        "\n",
        "        print(datetime.utcnow(),\n",
        "              \": <-- Объединение датафреймов в один и приведение к атомарности значений завершено -->\")\n",
        "\n",
        "    def analyze_create_features(self):\n",
        "        print(datetime.utcnow(), \": <-- Анализ объединенного датафрейма и создание фичей -->\")\n",
        "        print(\"Выведем типы для объединенного dataframe: \", self.df_merged.dtypes)\n",
        "        print(\"Выведем размерность для объединенного dataframe: \", self.df_merged.shape)\n",
        "        print(\"Выведем описательную статистику для объединенного dataframe: \", self.df_merged.describe())\n",
        "\n",
        "        print(self.df_merged)\n",
        "        print(datetime.utcnow(), \": <-- Анализ объединенного датафрейма и создание фичей -->\")\n",
        "\n",
        "    def select_features(self):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def clear_data_auxiliary(data_frame, data_frame_name, dropna=True):\n",
        "        print(datetime.utcnow(), \": Очищаем данные %s ..\" % data_frame_name)\n",
        "        if (dropna):\n",
        "            print(\"измерения %s до dropna():\" % data_frame_name, data_frame.shape)\n",
        "            data_frame = data_frame.dropna()\n",
        "        print(\"измерения %s до удаления пустых строк:\" % data_frame_name, data_frame.shape)\n",
        "        data_frame = data_frame.replace(r'^\\s*$', np.nan, regex=True)\n",
        "        print(\"измерения %s после очистки:\" % data_frame_name, data_frame.shape)\n",
        "        return data_frame\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mipt.magistr.sem1.mipt_python.pandas_hw.FeatureGenerator import FeatureGenerator\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # feature_generator = FeatureGenerator(r\"C:\\\\Users\\\\kM\\\\Downloads\\\\riiid-test-answer-prediction\\\\train.csv\")\n",
        "    generator = FeatureGenerator(r\"C:\\\\Users\\\\kM\\\\Downloads\\\\riiid-test-answer-prediction\\\\train.csv\",\n",
        "                                 r\"C:\\\\Users\\\\kM\\\\Downloads\\\\riiid-test-answer-prediction\\\\questions.csv\",\n",
        "                                 r\"C:\\\\Users\\\\kM\\\\Downloads\\\\riiid-test-answer-prediction\\\\lectures.csv\", nrows=300000)\n",
        "\n",
        "    generator.generate()"
      ],
      "metadata": {
        "id": "H6WNlb8u9lXk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}